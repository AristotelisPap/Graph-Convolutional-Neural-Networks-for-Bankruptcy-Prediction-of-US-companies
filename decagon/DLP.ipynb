{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Imports  { form-width: \"30%\" }\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.summary.writer.writer import FileWriter\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "np.random.seed(0)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "        \n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int64, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int64, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int64, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int64, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int64),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size = 0.05\n",
    "data_folder = \"./data/Full/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649079"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map for Organization ids\n",
    "orgIds_map = {}\n",
    "with open(data_folder + \"organizationIds.pickle\", \"rb\") as _orgf:\n",
    "    _index = 0\n",
    "    for _id in pickle.load(_orgf):\n",
    "        if _id not in orgIds_map:\n",
    "            orgIds_map[_index] =_id\n",
    "            _index += 1\n",
    "len(orgIds_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205178"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies, CCI = set(), {}\n",
    "\n",
    "with open(data_folder + \"Organization_Organization.csv\", encoding=\"utf8\") as _oof:\n",
    "    for line in _oof.readlines():\n",
    "        _cce = line.strip().split(\",\")\n",
    "        _c1, _c2, _e = _cce[0], _cce[1], _cce[2]\n",
    "        companies.add(_c1)\n",
    "        companies.add(_c2)\n",
    "        if _e not in CCI: CCI[_e] = CCI.get(_e, [])\n",
    "        CCI[_e].append((_c1, _c2))\n",
    "          \n",
    "n_companies = len(companies)  \n",
    "n_compcomp_rel_types = len(CCI)\n",
    "map_companies = {_p:_i for _i, _p in enumerate(list(companies))}\n",
    "n_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355642"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons, CPI = set(), {}\n",
    "\n",
    "with open(data_folder + \"Person_Organization.csv\") as _opf:\n",
    "    for _line in _opf.readlines():\n",
    "        _cpe = _line.strip().split(\",\")\n",
    "        _c, _p, _e = _cpe[0], _cpe[1], _cpe[2] \n",
    "        if _c in map_companies:\n",
    "            persons.add(_p)\n",
    "            if _e not in CPI: CPI[_e] = CPI.get(_e, [])\n",
    "            CPI[_e].append((_c, _p))\n",
    "\n",
    "n_persons = len(persons)\n",
    "map_persons = {_p:_i for _i, _p in enumerate(list(persons))}\n",
    "n_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "comp_comp_adj_list = []\n",
    "for _e in tqdm(CCI):\n",
    "    _mat = np.array([[map_companies[_u], map_companies[_v]] for _u, _v in CCI[_e]])\n",
    "    _data = np.ones(len(CCI[_e]))\n",
    "    comp_comp_adj_list.append(sp.csr_matrix((_data, (_mat[:, 0], _mat[:, 1])), shape=(n_companies, n_companies)))\n",
    "comp_degrees_list = [np.array(drug_adj.sum(axis=0)).squeeze() for drug_adj in comp_comp_adj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "pers_comp_adj_list = []\n",
    "for _e in tqdm(CPI):\n",
    "    _mat = np.array([[map_persons[_v], map_companies[_u]] for _u, _v in CPI[_e]])\n",
    "    _data = np.ones(len(CPI[_e]))\n",
    "    pers_comp_adj_list.append(sp.csr_matrix((_data, (_mat[:, 0], _mat[:, 1])), shape=(n_persons, n_companies)))\n",
    "pers_comp_degrees_list = [np.array(_adj.sum(axis=0)).squeeze() for _adj in pers_comp_adj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data representation\n",
    "adj_mats_orig = {\n",
    "#     (0, 0): [pers_adj, pers_adj.transpose(copy=True)],\n",
    "    (0, 1): pers_comp_adj_list,\n",
    "    (1, 0): [x.transpose(copy=True) for x in pers_comp_adj_list],\n",
    "    (1, 1): comp_comp_adj_list + [x.transpose(copy=True) for x in comp_comp_adj_list],\n",
    "#     (1, 2): [comp_bankr_adj],\n",
    "#     (2, 1): [bankr_comp_adj]\n",
    "}\n",
    "degrees = {\n",
    "    0: pers_comp_degrees_list,\n",
    "    1: comp_degrees_list + comp_degrees_list,\n",
    "#     2: [np.array([np.sum(bankr_comp_adj)]), np.array([np.sum(bankr_comp_adj)])]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureless (genes)\n",
    "pers_feat = sp.identity(n_persons)\n",
    "pers_nonzero_feat, pers_num_feat = pers_feat.shape\n",
    "pers_feat = preprocessing.sparse_to_tuple(pers_feat.tocoo())\n",
    "\n",
    "# features (drugs)\n",
    "comp_feat = sp.identity(n_companies)\n",
    "comp_nonzero_feat, comp_num_feat = comp_feat.shape\n",
    "comp_feat = preprocessing.sparse_to_tuple(comp_feat.tocoo())\n",
    "\n",
    "# features (drugs)\n",
    "# banrp_feat = sp.identity(n_bankruptcy)\n",
    "# banrp_nonzero_feat, banrp_num_feat = banrp_feat.shape\n",
    "# banrp_feat = preprocessing.sparse_to_tuple(banrp_feat.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 16\n"
     ]
    }
   ],
   "source": [
    "# data representation\n",
    "num_feat = {\n",
    "    0: pers_num_feat,\n",
    "    1: comp_num_feat,\n",
    "#     2: banrp_num_feat\n",
    "}\n",
    "nonzero_feat = {\n",
    "    0: pers_nonzero_feat,\n",
    "    1: comp_nonzero_feat,\n",
    "#     2: banrp_nonzero_feat\n",
    "}\n",
    "feat = {\n",
    "    0: pers_feat,\n",
    "    1: comp_feat,\n",
    "#     2: banrp_feat\n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "edge_type2decoder = {\n",
    "#     (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "#     (1, 2): 'bilinear',\n",
    "#     (2, 1): 'bilinear'\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "num_edge_types = sum(edge_types.values())\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Settings and placeholders\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 1, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 512, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch': <tf.Tensor 'batch:0' shape=<unknown> dtype=int64>,\n",
       " 'batch_edge_type_idx': <tf.Tensor 'batch_edge_type_idx:0' shape=() dtype=int64>,\n",
       " 'batch_row_edge_type': <tf.Tensor 'batch_row_edge_type:0' shape=() dtype=int64>,\n",
       " 'batch_col_edge_type': <tf.Tensor 'batch_col_edge_type:0' shape=() dtype=int64>,\n",
       " 'degrees': <tf.Tensor 'Placeholder:0' shape=<unknown> dtype=int64>,\n",
       " 'dropout': <tf.Tensor 'PlaceholderWithDefault:0' shape=() dtype=float32>,\n",
       " 'adj_mats_0,1,0': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246df85d630>,\n",
       " 'adj_mats_0,1,1': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246d1d1cd68>,\n",
       " 'adj_mats_0,1,2': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa14cc0>,\n",
       " 'adj_mats_0,1,3': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4e828>,\n",
       " 'adj_mats_1,0,0': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4ea90>,\n",
       " 'adj_mats_1,0,1': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4eb70>,\n",
       " 'adj_mats_1,0,2': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4f278>,\n",
       " 'adj_mats_1,0,3': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246df981080>,\n",
       " 'adj_mats_1,1,0': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4ff60>,\n",
       " 'adj_mats_1,1,1': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246dfa4fac8>,\n",
       " 'adj_mats_1,1,2': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683d8b2e8>,\n",
       " 'adj_mats_1,1,3': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683d8b6a0>,\n",
       " 'adj_mats_1,1,4': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683d8ba58>,\n",
       " 'adj_mats_1,1,5': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683d8be10>,\n",
       " 'adj_mats_1,1,6': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683da5208>,\n",
       " 'adj_mats_1,1,7': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683da55c0>,\n",
       " 'feat_0': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x24683da5978>,\n",
       " 'feat_1': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x246859e7400>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing test edges= 0000/14438\n",
      "Constructing test edges= 1000/14438\n",
      "Constructing test edges= 2000/14438\n",
      "Constructing test edges= 3000/14438\n",
      "Constructing test edges= 4000/14438\n",
      "Constructing test edges= 5000/14438\n",
      "Constructing test edges= 6000/14438\n",
      "Constructing test edges= 7000/14438\n",
      "Constructing test edges= 8000/14438\n",
      "Constructing test edges= 9000/14438\n",
      "Constructing test edges= 10000/14438\n",
      "Constructing test edges= 11000/14438\n",
      "Constructing test edges= 12000/14438\n",
      "Constructing test edges= 13000/14438\n",
      "Constructing test edges= 14000/14438\n",
      "Constructing val edges= 0000/14438\n",
      "Constructing val edges= 1000/14438\n",
      "Constructing val edges= 2000/14438\n",
      "Constructing val edges= 3000/14438\n",
      "Constructing val edges= 4000/14438\n",
      "Constructing val edges= 5000/14438\n",
      "Constructing val edges= 6000/14438\n",
      "Constructing val edges= 7000/14438\n",
      "Constructing val edges= 8000/14438\n",
      "Constructing val edges= 9000/14438\n",
      "Constructing val edges= 10000/14438\n",
      "Constructing val edges= 11000/14438\n",
      "Constructing val edges= 12000/14438\n",
      "Constructing val edges= 13000/14438\n",
      "Constructing val edges= 14000/14438\n",
      "Train edges= 259890\n",
      "Val edges= 14438\n",
      "Test edges= 14438\n",
      "Minibatch edge type: (0, 1, 1)\n",
      "Constructing test edges= 0000/6927\n",
      "Constructing test edges= 1000/6927\n",
      "Constructing test edges= 2000/6927\n",
      "Constructing test edges= 3000/6927\n",
      "Constructing test edges= 4000/6927\n",
      "Constructing test edges= 5000/6927\n",
      "Constructing test edges= 6000/6927\n",
      "Constructing val edges= 0000/6927\n",
      "Constructing val edges= 1000/6927\n",
      "Constructing val edges= 2000/6927\n",
      "Constructing val edges= 3000/6927\n",
      "Constructing val edges= 4000/6927\n",
      "Constructing val edges= 5000/6927\n",
      "Constructing val edges= 6000/6927\n",
      "Train edges= 124689\n",
      "Val edges= 6927\n",
      "Test edges= 6927\n",
      "Minibatch edge type: (0, 1, 2)\n",
      "Constructing test edges= 0000/6631\n",
      "Constructing test edges= 1000/6631\n",
      "Constructing test edges= 2000/6631\n",
      "Constructing test edges= 3000/6631\n",
      "Constructing test edges= 4000/6631\n",
      "Constructing test edges= 5000/6631\n",
      "Constructing test edges= 6000/6631\n",
      "Constructing val edges= 0000/6631\n",
      "Constructing val edges= 1000/6631\n",
      "Constructing val edges= 2000/6631\n",
      "Constructing val edges= 3000/6631\n",
      "Constructing val edges= 4000/6631\n",
      "Constructing val edges= 5000/6631\n",
      "Constructing val edges= 6000/6631\n",
      "Train edges= 119369\n",
      "Val edges= 6631\n",
      "Test edges= 6631\n",
      "Minibatch edge type: (0, 1, 3)\n",
      "Constructing test edges= 0000/1592\n",
      "Constructing test edges= 1000/1592\n",
      "Constructing val edges= 0000/1592\n",
      "Constructing val edges= 1000/1592\n",
      "Train edges= 28661\n",
      "Val edges= 1592\n",
      "Test edges= 1592\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing test edges= 0000/14438\n",
      "Constructing test edges= 1000/14438\n",
      "Constructing test edges= 2000/14438\n",
      "Constructing test edges= 3000/14438\n",
      "Constructing test edges= 4000/14438\n",
      "Constructing test edges= 5000/14438\n",
      "Constructing test edges= 6000/14438\n",
      "Constructing test edges= 7000/14438\n",
      "Constructing test edges= 8000/14438\n",
      "Constructing test edges= 9000/14438\n",
      "Constructing test edges= 10000/14438\n",
      "Constructing test edges= 11000/14438\n",
      "Constructing test edges= 12000/14438\n",
      "Constructing test edges= 13000/14438\n",
      "Constructing test edges= 14000/14438\n",
      "Constructing val edges= 0000/14438\n",
      "Constructing val edges= 1000/14438\n",
      "Constructing val edges= 2000/14438\n",
      "Constructing val edges= 3000/14438\n",
      "Constructing val edges= 4000/14438\n",
      "Constructing val edges= 5000/14438\n",
      "Constructing val edges= 6000/14438\n",
      "Constructing val edges= 7000/14438\n",
      "Constructing val edges= 8000/14438\n",
      "Constructing val edges= 9000/14438\n",
      "Constructing val edges= 10000/14438\n",
      "Constructing val edges= 11000/14438\n",
      "Constructing val edges= 12000/14438\n",
      "Constructing val edges= 13000/14438\n",
      "Constructing val edges= 14000/14438\n",
      "Train edges= 259890\n",
      "Val edges= 14438\n",
      "Test edges= 14438\n",
      "Minibatch edge type: (1, 0, 1)\n",
      "Constructing test edges= 0000/6927\n",
      "Constructing test edges= 1000/6927\n",
      "Constructing test edges= 2000/6927\n",
      "Constructing test edges= 3000/6927\n",
      "Constructing test edges= 4000/6927\n",
      "Constructing test edges= 5000/6927\n",
      "Constructing test edges= 6000/6927\n",
      "Constructing val edges= 0000/6927\n",
      "Constructing val edges= 1000/6927\n",
      "Constructing val edges= 2000/6927\n",
      "Constructing val edges= 3000/6927\n",
      "Constructing val edges= 4000/6927\n",
      "Constructing val edges= 5000/6927\n",
      "Constructing val edges= 6000/6927\n",
      "Train edges= 124689\n",
      "Val edges= 6927\n",
      "Test edges= 6927\n",
      "Minibatch edge type: (1, 0, 2)\n",
      "Constructing test edges= 0000/6631\n",
      "Constructing test edges= 1000/6631\n",
      "Constructing test edges= 2000/6631\n",
      "Constructing test edges= 3000/6631\n",
      "Constructing test edges= 4000/6631\n",
      "Constructing test edges= 5000/6631\n",
      "Constructing test edges= 6000/6631\n",
      "Constructing val edges= 0000/6631\n",
      "Constructing val edges= 1000/6631\n",
      "Constructing val edges= 2000/6631\n",
      "Constructing val edges= 3000/6631\n",
      "Constructing val edges= 4000/6631\n",
      "Constructing val edges= 5000/6631\n",
      "Constructing val edges= 6000/6631\n",
      "Train edges= 119369\n",
      "Val edges= 6631\n",
      "Test edges= 6631\n",
      "Minibatch edge type: (1, 0, 3)\n",
      "Constructing test edges= 0000/1592\n",
      "Constructing test edges= 1000/1592\n",
      "Constructing val edges= 0000/1592\n",
      "Constructing val edges= 1000/1592\n",
      "Train edges= 28661\n",
      "Val edges= 1592\n",
      "Test edges= 1592\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Constructing test edges= 0000/5912\n",
      "Constructing test edges= 1000/5912\n",
      "Constructing test edges= 2000/5912\n",
      "Constructing test edges= 3000/5912\n",
      "Constructing test edges= 4000/5912\n",
      "Constructing test edges= 5000/5912\n",
      "Constructing val edges= 0000/5912\n",
      "Constructing val edges= 1000/5912\n",
      "Constructing val edges= 2000/5912\n",
      "Constructing val edges= 3000/5912\n",
      "Constructing val edges= 4000/5912\n",
      "Constructing val edges= 5000/5912\n",
      "Train edges= 106418\n",
      "Val edges= 5912\n",
      "Test edges= 5912\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Constructing test edges= 0000/0414\n",
      "Constructing val edges= 0000/0414\n",
      "Train edges= 7469\n",
      "Val edges= 0414\n",
      "Test edges= 0414\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Constructing test edges= 0000/11081\n",
      "Constructing test edges= 1000/11081\n",
      "Constructing test edges= 2000/11081\n",
      "Constructing test edges= 3000/11081\n",
      "Constructing test edges= 4000/11081\n",
      "Constructing test edges= 5000/11081\n",
      "Constructing test edges= 6000/11081\n",
      "Constructing test edges= 7000/11081\n",
      "Constructing test edges= 8000/11081\n",
      "Constructing test edges= 9000/11081\n",
      "Constructing test edges= 10000/11081\n",
      "Constructing test edges= 11000/11081\n",
      "Constructing val edges= 0000/11081\n",
      "Constructing val edges= 1000/11081\n",
      "Constructing val edges= 2000/11081\n",
      "Constructing val edges= 3000/11081\n",
      "Constructing val edges= 4000/11081\n",
      "Constructing val edges= 5000/11081\n",
      "Constructing val edges= 6000/11081\n",
      "Constructing val edges= 7000/11081\n",
      "Constructing val edges= 8000/11081\n",
      "Constructing val edges= 9000/11081\n",
      "Constructing val edges= 10000/11081\n",
      "Constructing val edges= 11000/11081\n",
      "Train edges= 199469\n",
      "Val edges= 11081\n",
      "Test edges= 11081\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Constructing test edges= 0000/0482\n",
      "Constructing val edges= 0000/0482\n",
      "Train edges= 8683\n",
      "Val edges= 0482\n",
      "Test edges= 0482\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Constructing test edges= 0000/5912\n",
      "Constructing test edges= 1000/5912\n",
      "Constructing test edges= 2000/5912\n",
      "Constructing test edges= 3000/5912\n",
      "Constructing test edges= 4000/5912\n",
      "Constructing test edges= 5000/5912\n",
      "Constructing val edges= 0000/5912\n",
      "Constructing val edges= 1000/5912\n",
      "Constructing val edges= 2000/5912\n",
      "Constructing val edges= 3000/5912\n",
      "Constructing val edges= 4000/5912\n",
      "Constructing val edges= 5000/5912\n",
      "Train edges= 106418\n",
      "Val edges= 5912\n",
      "Test edges= 5912\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Constructing test edges= 0000/0414\n",
      "Constructing val edges= 0000/0414\n",
      "Train edges= 7469\n",
      "Val edges= 0414\n",
      "Test edges= 0414\n",
      "Minibatch edge type: (1, 1, 6)\n",
      "Constructing test edges= 0000/11081\n",
      "Constructing test edges= 1000/11081\n",
      "Constructing test edges= 2000/11081\n",
      "Constructing test edges= 3000/11081\n",
      "Constructing test edges= 4000/11081\n",
      "Constructing test edges= 5000/11081\n",
      "Constructing test edges= 6000/11081\n",
      "Constructing test edges= 7000/11081\n",
      "Constructing test edges= 8000/11081\n",
      "Constructing test edges= 9000/11081\n",
      "Constructing test edges= 10000/11081\n",
      "Constructing test edges= 11000/11081\n",
      "Constructing val edges= 0000/11081\n",
      "Constructing val edges= 1000/11081\n",
      "Constructing val edges= 2000/11081\n",
      "Constructing val edges= 3000/11081\n",
      "Constructing val edges= 4000/11081\n",
      "Constructing val edges= 5000/11081\n",
      "Constructing val edges= 6000/11081\n",
      "Constructing val edges= 7000/11081\n",
      "Constructing val edges= 8000/11081\n",
      "Constructing val edges= 9000/11081\n",
      "Constructing val edges= 10000/11081\n",
      "Constructing val edges= 11000/11081\n",
      "Train edges= 199469\n",
      "Val edges= 11081\n",
      "Test edges= 11081\n",
      "Minibatch edge type: (1, 1, 7)\n",
      "Constructing test edges= 0000/0482\n",
      "Constructing val edges= 0000/0482\n",
      "Train edges= 8683\n",
      "Val edges= 0482\n",
      "Test edges= 0482\n"
     ]
    }
   ],
   "source": [
    "# Create minibatch iterator\n",
    "\n",
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "WARNING:tensorflow:From C:\\Users\\ishan\\Desktop\\DL\\Project\\decagon-master\\decagon\\deep\\layers.py:93: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishan\\Anaconda3\\envs\\AS1\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "\n",
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )\n",
    "\n",
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "# FileWriter(\"output\", sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Train model\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        \n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "        \n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "print(\"Optimization finished!\")\n",
    "\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
